#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•åªçˆ¬å–æ—¥è¯­ç‰ˆæœ¬çš„ 536VOLA-001 ç”µå½±è¯¦æƒ…
ä¸è®¿é—®ä¸»é¡µï¼Œç›´æ¥è®¿é—®ç”µå½±ä»£ç å¯¹åº”çš„é¡µé¢è·å–HTMLå†…å®¹
"""

import asyncio
import logging
import sys
import os
import time
import json
from pathlib import Path
from unittest.mock import Mock, AsyncMock
from typing import Dict, List, Any, Optional
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root / "src"))

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class BatchMovieCrawler:
    """æ‰¹é‡ç”µå½±çˆ¬è™«ç±»"""
    
    def __init__(self, language="ja"):
        self.language = language
        
        # åˆ›å»ºæµè§ˆå™¨æ•°æ®æŒä¹…åŒ–ç›®å½•
        self.user_data_dir = Path.home() / ".cache" / "cloudflare_bypass_browser"
        self.user_data_dir.mkdir(parents=True, exist_ok=True)
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®ç›®å½•
        self.test_data_dir = Path("test_536VOLA_data")
        self.test_data_dir.mkdir(exist_ok=True)
    
    def crawl_movies_single_browser(self, movie_codes, output_file="batch_results.jsonl"):
        """ä½¿ç”¨å•ä¸ªæµè§ˆå™¨å®ä¾‹æ‰¹é‡çˆ¬å–ç”µå½±ä¿¡æ¯
        
        Args:
            movie_codes: ç”µå½±ä»£ç åˆ—è¡¨ï¼Œå¦‚ ['VOLA-001', 'HZHB-004']
            output_file: è¾“å‡ºJSONæ–‡ä»¶å
        
        Returns:
            dict: çˆ¬å–ç»“æœç»Ÿè®¡å’Œæ•°æ®
        """
        results = {
            'success': [],
            'failed': [],
            'total': len(movie_codes),
            'movies': {}  # å­˜å‚¨æ‰€æœ‰ç”µå½±æ•°æ®
        }
        
        browser = None
        try:
            logger.info(f"å¼€å§‹æ‰¹é‡çˆ¬å– {len(movie_codes)} ä¸ªç”µå½±ï¼ˆä½¿ç”¨å•ä¸ªæµè§ˆå™¨å®ä¾‹ï¼‰")
            
            # åˆ›å»ºæµè§ˆå™¨å®ä¾‹ï¼ˆæ— å¤´æ¨¡å¼ï¼‰
            from app.utils.drission_utils import CloudflareBypassBrowser
            from test.test_drission_movie import MovieDetailCrawler
            
            browser = CloudflareBypassBrowser(
                headless=True,
                user_data_dir=str(self.user_data_dir),
                load_images=True,
                timeout=60
            )
            
            # é€ä¸ªå¤„ç†ç”µå½±ä»£ç 
            for i, movie_code in enumerate(movie_codes, 1):
                logger.info(f"\n[{i}/{len(movie_codes)}] æ­£åœ¨å¤„ç†: {movie_code}")
                
                try:
                    movie_info = self._crawl_single_movie_with_browser(browser, movie_code)
                    if movie_info and movie_info.get('title'):
                        results['success'].append(movie_code)
                        results['movies'][movie_code] = movie_info
                        logger.info(f"âœ… {movie_code} çˆ¬å–æˆåŠŸ")
                    else:
                        results['failed'].append(movie_code)
                        logger.error(f"âŒ {movie_code} çˆ¬å–å¤±è´¥ï¼šæœªè·å–åˆ°æœ‰æ•ˆä¿¡æ¯")
                except Exception as e:
                    results['failed'].append(movie_code)
                    logger.error(f"âŒ {movie_code} çˆ¬å–å¤±è´¥ï¼š{str(e)}")
                
                # æ·»åŠ å»¶è¿Ÿé¿å…è¯·æ±‚è¿‡å¿«
                if i < len(movie_codes):
                    time.sleep(2)
            
            # ä¿å­˜æ‰€æœ‰ç»“æœåˆ°JSONLæ–‡ä»¶ï¼ˆæ¯è¡Œä¸€ä¸ªJSONå¯¹è±¡ï¼‰
            output_path = self.test_data_dir / output_file
            with open(output_path, 'w', encoding='utf-8') as f:
                for movie_code, movie_info in results['movies'].items():
                    # æ¯è¡Œå†™å…¥ä¸€ä¸ªå®Œæ•´çš„JSONå¯¹è±¡
                    json_line = json.dumps(movie_info, ensure_ascii=False)
                    f.write(json_line + '\n')
            
            logger.info(f"\nç»“æœå·²ä¿å­˜åˆ°JSONLæ ¼å¼æ–‡ä»¶: {output_path}")
            logger.info(f"JSONLæ ¼å¼è¯´æ˜: æ¯è¡Œæ˜¯ä¸€ä¸ªç‹¬ç«‹çš„JSONå¯¹è±¡ï¼Œæ”¯æŒæµå¼å¤„ç†å¤§é‡æ•°æ®")
            
        except Exception as e:
            logger.error(f"æ‰¹é‡çˆ¬å–è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        finally:
            if browser is not None:
                browser.close()
                logger.info("æµè§ˆå™¨å·²å…³é—­")
        
        # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
        logger.info("\n=== æ‰¹é‡çˆ¬å–å®Œæˆ ===")
        logger.info(f"æ€»æ•°: {results['total']}")
        logger.info(f"æˆåŠŸ: {len(results['success'])}")
        logger.info(f"å¤±è´¥: {len(results['failed'])}")
        
        if results['success']:
            logger.info(f"æˆåŠŸåˆ—è¡¨: {', '.join(results['success'])}")
        if results['failed']:
            logger.info(f"å¤±è´¥åˆ—è¡¨: {', '.join(results['failed'])}")
        
        return results
    
    def crawl_movies_concurrent_tabs(self, movie_codes, output_file="batch_results_concurrent.jsonl", max_tabs=3):
        """ä½¿ç”¨å•ä¸ªæµè§ˆå™¨çš„å¤šä¸ªæ ‡ç­¾é¡µå¹¶å‘çˆ¬å–ç”µå½±ä¿¡æ¯
        
        Args:
            movie_codes: ç”µå½±ä»£ç åˆ—è¡¨ï¼Œå¦‚ ['VOLA-001', 'HZHB-004']
            output_file: è¾“å‡ºJSONLæ–‡ä»¶å
            max_tabs: æœ€å¤§å¹¶å‘æ ‡ç­¾é¡µæ•°é‡ï¼ˆå»ºè®®2-4ä¸ªï¼Œé¿å…è¿‡å¤šå ç”¨èµ„æºï¼‰
        
        Returns:
            dict: çˆ¬å–ç»“æœç»Ÿè®¡å’Œæ•°æ®
        """
        results = {
            'success': [],
            'failed': [],
            'total': len(movie_codes),
            'movies': {}  # å­˜å‚¨æ‰€æœ‰ç”µå½±æ•°æ®
        }
        
        browser = None
        lock = threading.Lock()  # ç”¨äºçº¿ç¨‹å®‰å…¨çš„ç»“æœæ›´æ–°
        
        try:
            logger.info(f"å¼€å§‹å¹¶å‘æ‰¹é‡çˆ¬å– {len(movie_codes)} ä¸ªç”µå½±ï¼ˆæœ€å¤š {max_tabs} ä¸ªå¹¶å‘æ ‡ç­¾é¡µï¼‰")
            
            # åˆ›å»ºæµè§ˆå™¨å®ä¾‹ï¼ˆæ— å¤´æ¨¡å¼ï¼‰
            from app.utils.drission_utils import CloudflareBypassBrowser
            from test.test_drission_movie import MovieDetailCrawler
            
            browser = CloudflareBypassBrowser(
                headless=True,
                user_data_dir=str(self.user_data_dir),
                load_images=True,
                timeout=60
            )
            
            def crawl_single_movie_in_tab(movie_code):
                """åœ¨æ–°æ ‡ç­¾é¡µä¸­çˆ¬å–å•ä¸ªç”µå½±"""
                tab = None
                try:
                    # æ£€æŸ¥æµè§ˆå™¨å¯¹è±¡æ˜¯å¦æœ‰æ•ˆ
                    if browser is None:
                        raise Exception("æµè§ˆå™¨å¯¹è±¡ä¸ºç©º")
                    
                    # åˆ›å»ºæ–°æ ‡ç­¾é¡µ
                    tab = browser.page.new_tab()
                    if tab is None:
                        raise Exception("æ— æ³•åˆ›å»ºæ–°æ ‡ç­¾é¡µ")
                    
                    logger.info(f"[æ ‡ç­¾é¡µ] æ­£åœ¨å¤„ç†: {movie_code}")
                    
                    # æ„å»ºURLå¹¶è®¿é—®
                    url = f"https://missav.ai/{self.language}/{movie_code}"
                    tab.get(url)
                    
                    # ç­‰å¾…é¡µé¢åŠ è½½
                    time.sleep(3)
                    
                    # è§£æç”µå½±ä¿¡æ¯
                    crawler = MovieDetailCrawler(movie_code)
                    html_content = tab.html
                    movie_info = crawler.parse_movie_page(html_content)
                    
                    # çº¿ç¨‹å®‰å…¨åœ°æ›´æ–°ç»“æœ
                    with lock:
                        if movie_info and movie_info.get('title'):
                            results['success'].append(movie_code)
                            results['movies'][movie_code] = movie_info
                            logger.info(f"âœ… [æ ‡ç­¾é¡µ] {movie_code} çˆ¬å–æˆåŠŸ")
                        else:
                            results['failed'].append(movie_code)
                            logger.error(f"âŒ [æ ‡ç­¾é¡µ] {movie_code} çˆ¬å–å¤±è´¥ï¼šæœªè·å–åˆ°æœ‰æ•ˆä¿¡æ¯")
                    
                    return movie_code, True
                    
                except Exception as e:
                    with lock:
                        results['failed'].append(movie_code)
                        logger.error(f"âŒ [æ ‡ç­¾é¡µ] {movie_code} çˆ¬å–å¤±è´¥ï¼š{str(e)}")
                    return movie_code, False
                finally:
                    if tab:
                        try:
                            tab.close()
                        except:
                            pass
            
            # ä½¿ç”¨çº¿ç¨‹æ± è¿›è¡Œå¹¶å‘å¤„ç†
            with ThreadPoolExecutor(max_workers=max_tabs) as executor:
                # æäº¤æ‰€æœ‰ä»»åŠ¡
                future_to_movie = {executor.submit(crawl_single_movie_in_tab, movie_code): movie_code 
                                 for movie_code in movie_codes}
                
                # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
                for future in as_completed(future_to_movie):
                    movie_code = future_to_movie[future]
                    try:
                        future.result()
                    except Exception as e:
                        logger.error(f"çº¿ç¨‹æ‰§è¡Œå¼‚å¸¸ {movie_code}: {str(e)}")
            
            # ä¿å­˜æ‰€æœ‰ç»“æœåˆ°JSONLæ–‡ä»¶ï¼ˆæ¯è¡Œä¸€ä¸ªJSONå¯¹è±¡ï¼‰
            output_path = self.test_data_dir / output_file
            with open(output_path, 'w', encoding='utf-8') as f:
                for movie_code, movie_info in results['movies'].items():
                    # æ¯è¡Œå†™å…¥ä¸€ä¸ªå®Œæ•´çš„JSONå¯¹è±¡
                    json_line = json.dumps(movie_info, ensure_ascii=False)
                    f.write(json_line + '\n')
            
            logger.info(f"\nå¹¶å‘çˆ¬å–ç»“æœå·²ä¿å­˜åˆ°JSONLæ ¼å¼æ–‡ä»¶: {output_path}")
            logger.info(f"å¹¶å‘ä¼˜åŠ¿: ä½¿ç”¨ {max_tabs} ä¸ªæ ‡ç­¾é¡µåŒæ—¶å¤„ç†ï¼Œå¤§å¹…æå‡çˆ¬å–é€Ÿåº¦")
            
        except Exception as e:
            logger.error(f"å¹¶å‘æ‰¹é‡çˆ¬å–è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        finally:
            if browser is not None:
                browser.close()
                logger.info("æµè§ˆå™¨å·²å…³é—­")
        
        # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
        logger.info("\n=== å¹¶å‘æ‰¹é‡çˆ¬å–å®Œæˆ ===")
        logger.info(f"æ€»æ•°: {results['total']}")
        logger.info(f"æˆåŠŸ: {len(results['success'])}")
        logger.info(f"å¤±è´¥: {len(results['failed'])}")
        
        if results['success']:
            logger.info(f"æˆåŠŸåˆ—è¡¨: {', '.join(results['success'])}")
        if results['failed']:
            logger.info(f"å¤±è´¥åˆ—è¡¨: {', '.join(results['failed'])}")
        
        return results
    
    def _crawl_single_movie_with_browser(self, browser, movie_code):
        """ä½¿ç”¨å·²æœ‰æµè§ˆå™¨å®ä¾‹çˆ¬å–å•ä¸ªç”µå½±ä¿¡æ¯"""
        try:
            from test.test_drission_movie import MovieDetailCrawler
            
            # æ„å»ºç”µå½±é¡µé¢URL
            movie_url = f"https://missav.ai/{self.language}/{movie_code}"
            logger.info(f"è®¿é—®URL: {movie_url}")
            
            # è®¿é—®ç”µå½±é¡µé¢
            browser.get(movie_url)
            time.sleep(3)
            
            # è·å–é¡µé¢HTML
            html_content = browser.get_html()
            
            # åˆ›å»ºè§£æå™¨å¹¶è§£æ
            crawler = MovieDetailCrawler(movie_code)
            movie_info = crawler.parse_movie_page(html_content)
            
            # ä¿å­˜HTMLæ–‡ä»¶ï¼ˆå¯é€‰ï¼‰
            html_file = self.test_data_dir / f"{movie_code}_{self.language}.html"
            with open(html_file, 'w', encoding='utf-8') as f:
                f.write(html_content)
            
            return movie_info
            
        except Exception as e:
            logger.error(f"çˆ¬å– {movie_code} æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            raise
    
    def crawl_movies(self, movie_codes):
        """æ‰¹é‡çˆ¬å–ç”µå½±ä¿¡æ¯
        
        Args:
            movie_codes: ç”µå½±ä»£ç åˆ—è¡¨ï¼Œå¦‚ ['VOLA-001', 'HZHB-004']
        
        Returns:
            dict: çˆ¬å–ç»“æœç»Ÿè®¡
        """
        results = {
            'success': [],
            'failed': [],
            'total': len(movie_codes)
        }
        
        logger.info(f"å¼€å§‹æ‰¹é‡çˆ¬å– {len(movie_codes)} ä¸ªç”µå½±")
        
        for i, movie_code in enumerate(movie_codes, 1):
            logger.info(f"\n[{i}/{len(movie_codes)}] æ­£åœ¨å¤„ç†: {movie_code}")
            
            try:
                movie_info = self._crawl_single_movie(movie_code)
                if movie_info and movie_info.get('title'):
                    results['success'].append(movie_code)
                    logger.info(f"âœ… {movie_code} çˆ¬å–æˆåŠŸ")
                else:
                    results['failed'].append(movie_code)
                    logger.error(f"âŒ {movie_code} çˆ¬å–å¤±è´¥ï¼šæœªè·å–åˆ°æœ‰æ•ˆä¿¡æ¯")
            except Exception as e:
                results['failed'].append(movie_code)
                logger.error(f"âŒ {movie_code} çˆ¬å–å¤±è´¥ï¼š{str(e)}")
            
            # æ·»åŠ å»¶è¿Ÿé¿å…è¯·æ±‚è¿‡å¿«
            if i < len(movie_codes):
                time.sleep(2)
        
        # è¾“å‡ºç»Ÿè®¡ç»“æœ
        logger.info(f"\n=== æ‰¹é‡çˆ¬å–å®Œæˆ ===")
        logger.info(f"æ€»æ•°: {results['total']}")
        logger.info(f"æˆåŠŸ: {len(results['success'])}")
        logger.info(f"å¤±è´¥: {len(results['failed'])}")
        
        if results['success']:
            logger.info(f"æˆåŠŸåˆ—è¡¨: {', '.join(results['success'])}")
        if results['failed']:
            logger.info(f"å¤±è´¥åˆ—è¡¨: {', '.join(results['failed'])}")
        
        return results
    
    def _crawl_single_movie(self, movie_code):
        """çˆ¬å–å•ä¸ªç”µå½±ä¿¡æ¯"""
        browser = None
        try:
            # åˆ›å»ºæµè§ˆå™¨å®ä¾‹ï¼ˆæ— å¤´æ¨¡å¼ï¼‰
            from app.utils.drission_utils import CloudflareBypassBrowser
            from test.test_drission_movie import MovieDetailCrawler
            
            browser = CloudflareBypassBrowser(
                headless=True,
                user_data_dir=str(self.user_data_dir),
                load_images=True,
                timeout=60
            )
            
            # æ„å»ºç”µå½±é¡µé¢URL
            movie_url = f"https://missav.ai/{self.language}/{movie_code}"
            logger.info(f"è®¿é—®URL: {movie_url}")
            
            # è®¿é—®ç”µå½±é¡µé¢
            browser.get(movie_url)
            time.sleep(3)
            
            # è·å–é¡µé¢HTML
            html_content = browser.get_html()
            
            # åˆ›å»ºè§£æå™¨å¹¶è§£æ
            crawler = MovieDetailCrawler(movie_code)
            movie_info = crawler.parse_movie_page(html_content)
            
            # ä¿å­˜HTMLå’Œè§£æç»“æœ
            html_file = self.test_data_dir / f"{movie_code}_{self.language}.html"
            with open(html_file, 'w', encoding='utf-8') as f:
                f.write(html_content)
            
            json_file = self.test_data_dir / f"{movie_code}_{self.language}_parsed.json"
            with open(json_file, 'w', encoding='utf-8') as f:
                json.dump(movie_info, f, ensure_ascii=False, indent=2)
            
            browser.quit()
            return movie_info
            
        except Exception as e:
            logger.error(f"çˆ¬å– {movie_code} æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            if browser is not None:
                try:
                    browser.quit()
                except:
                    pass
            raise


class TestJAOnly536VOLA001:
    """æµ‹è¯•åªçˆ¬å–æ—¥è¯­ç‰ˆæœ¬çš„ 536VOLA-001 ç”µå½±è¯¦æƒ…"""
    
    def __init__(self):
        self.movie_code = "HZHB-004"
        self.language = "ja"  # åªçˆ¬å–æ—¥è¯­ç‰ˆæœ¬
    
    async def setup_service(self):
        """è®¾ç½®æµ‹è¯•æœåŠ¡"""
        try:
            from crawler.service.movie_detail_crawler_service import MovieDetailCrawlerService
            
            # åˆ›å»ºæ¨¡æ‹Ÿçš„ä¾èµ–é¡¹
            mock_crawler_progress_service = Mock()
            mock_movie_info_repository = Mock()
            mock_movie_repository = Mock()
            mock_download_url_repository = Mock()
            
            # æ¨¡æ‹Ÿæ•°æ®åº“ä¿å­˜æ“ä½œ
            mock_movie_info_repository.save = AsyncMock(return_value=True)
            mock_movie_repository.save = AsyncMock(return_value=True)
            mock_download_url_repository.save = AsyncMock(return_value=True)
            
            # åˆ›å»ºæœåŠ¡å®ä¾‹
            service = MovieDetailCrawlerService(
                crawler_progress_service=mock_crawler_progress_service,
                movie_info_repository=mock_movie_info_repository,
                movie_repository=mock_movie_repository,
                download_url_repository=mock_download_url_repository
            )
            
            logger.info("âœ… æœåŠ¡å®ä¾‹åˆ›å»ºæˆåŠŸ")
            return service
            
        except Exception as e:
            logger.error(f"âŒ åˆ›å»ºæœåŠ¡å®ä¾‹å¤±è´¥: {str(e)}")
            return None
    
    async def test_direct_movie_page_crawl(self):
        """æµ‹è¯•ç›´æ¥è®¿é—®ç”µå½±é¡µé¢è¿›è¡Œçˆ¬å–å’Œè§£æï¼ˆä¸ä¿å­˜æ•°æ®åº“ï¼‰"""
        logger.info(f"=== æµ‹è¯•ç›´æ¥è®¿é—®ç”µå½±é¡µé¢: {self.movie_code} (è¯­è¨€: {self.language}) ===")
        
        try:
            # åˆ›å»ºæµè§ˆå™¨å®ä¾‹ï¼ˆæ— å¤´æ¨¡å¼ï¼‰
            from app.utils.drission_utils import CloudflareBypassBrowser
            from test.test_drission_movie import MovieDetailCrawler
            
            browser = CloudflareBypassBrowser(headless=True)
            
            # æ„å»ºç”µå½±é¡µé¢URL
            movie_url = f"https://missav.ai/{self.language}/{self.movie_code}"
            logger.info(f"è®¿é—®URL: {movie_url}")
            
            # ç›´æ¥è®¿é—®ç”µå½±é¡µé¢
            success = browser.get(movie_url)
            if not success:
                logger.error("âŒ æ— æ³•è®¿é—®ç”µå½±é¡µé¢")
                browser.quit()
                return False
            
            # è·å–é¡µé¢HTMLå†…å®¹
            html_content = browser.get_html()
            if not html_content:
                logger.error("âŒ æ— æ³•è·å–HTMLå†…å®¹")
                browser.quit()
                return False
            
            logger.info(f"âœ… æˆåŠŸè·å–HTMLå†…å®¹ï¼Œé•¿åº¦: {len(html_content)} å­—ç¬¦")
            
            # è§£æç”µå½±ä¿¡æ¯
            parser = MovieDetailCrawler(self.movie_code)
            movie_info = parser.parse_movie_page(html_content)
            
            # æ£€æŸ¥è§£æç»“æœ
            if not movie_info or not isinstance(movie_info, dict):
                logger.error(f"âŒ ç”µå½± {self.movie_code} è§£æå¤±è´¥ï¼Œæœªè·å¾—æœ‰æ•ˆæ•°æ®")
                browser.quit()
                return False
            
            logger.info(f"âœ… ç”µå½± {self.movie_code} æ—¥è¯­ç‰ˆæœ¬è§£ææˆåŠŸ")
            
            # æå–æµåª’ä½“URL
            def safe_run_js(script):
                try:
                    return browser.run_js(script)
                except Exception as e:
                    logger.warning(f"æ‰§è¡ŒJavaScriptå¤±è´¥: {str(e)}")
                    return None
            
            stream_script = """
            function() {
                const streamUrls = [];
                const scripts = document.querySelectorAll('script');
                for (const script of scripts) {
                    const content = script.textContent || '';
                    if (content.includes('m3u8')) {
                        const m3u8Matches = content.match(/https?:\/\/[^"']+\.m3u8[^"']*/g);
                        if (m3u8Matches) {
                            streamUrls.push(...m3u8Matches);
                        }
                    }
                }
                return streamUrls;
            }
            """
            
            stream_urls = safe_run_js(stream_script)
            if stream_urls and isinstance(stream_urls, list):
                movie_info["stream_urls"] = stream_urls
                logger.info(f"æ‰¾åˆ° {len(stream_urls)} ä¸ªæµåª’ä½“URL")
            
            # æ˜¾ç¤ºè§£æç»“æœ
            title = movie_info.get('title', 'æœªçŸ¥')
            logger.info(f"  æ ‡é¢˜: {title[:100]}")
            
            actresses = movie_info.get('actresses', [])
            logger.info(f"  å¥³ä¼˜: {', '.join(actresses)}")
            
            duration = movie_info.get('duration_seconds', 0) or 0
            if duration > 0:
                logger.info(f"  æ—¶é•¿: {duration} ç§’ ({duration//60}åˆ†{duration%60}ç§’)")
            else:
                logger.info(f"  æ—¶é•¿: æœªçŸ¥")
            
            release_date = movie_info.get('release_date', 'æœªçŸ¥')
            logger.info(f"  å‘å¸ƒæ—¥æœŸ: {release_date}")
            
            genres = movie_info.get('genres', [])
            logger.info(f"  ç±»å‹: {', '.join(genres)}")
            
            # æ£€æŸ¥è¯­è¨€
            language = movie_info.get('language', 'æœªçŸ¥')
            logger.info(f"  è¯­è¨€: {language}")
            
            # æ£€æŸ¥æµåª’ä½“URL
            stream_urls = movie_info.get('stream_urls', [])
            if stream_urls:
                logger.info(f"  âœ… æ‰¾åˆ° {len(stream_urls)} ä¸ªæµåª’ä½“URL")
                for i, url in enumerate(stream_urls[:3]):  # åªæ˜¾ç¤ºå‰3ä¸ª
                    logger.info(f"    URL {i+1}: {url[:100]}...")
            else:
                logger.info("  âš ï¸  æœªæ‰¾åˆ°æµåª’ä½“URL")
            
            # æ£€æŸ¥M3U8ä¿¡æ¯
            m3u8_info = movie_info.get('m3u8_info', {})
            if m3u8_info:
                logger.info(f"  âœ… æ‰¾åˆ°M3U8ä¿¡æ¯")
                logger.info(f"    åŠ å¯†ä»£ç é•¿åº¦: {len(str(m3u8_info.get('encrypted_code', '')))}")
                logger.info(f"    å­—å…¸é”®æ•°é‡: {len(m3u8_info.get('dictionary', {}))}")
            else:
                logger.info("  âš ï¸  æœªæ‰¾åˆ°M3U8ä¿¡æ¯")
            
            # ä¿å­˜HTMLå†…å®¹ç”¨äºè°ƒè¯•
            html_file = f"test_536VOLA_data/{self.movie_code}_{self.language}.html"
            os.makedirs("test_536VOLA_data", exist_ok=True)
            with open(html_file, 'w', encoding='utf-8') as f:
                f.write(html_content)
            logger.info(f"  ğŸ’¾ HTMLå†…å®¹å·²ä¿å­˜åˆ°: {html_file}")
            
            # ä¿å­˜è§£æç»“æœç”¨äºè°ƒè¯•
            import json
            json_file = f"test_536VOLA_data/{self.movie_code}_{self.language}_parsed.json"
            with open(json_file, 'w', encoding='utf-8') as f:
                json.dump(movie_info, f, ensure_ascii=False, indent=2)
            logger.info(f"  ğŸ’¾ è§£æç»“æœå·²ä¿å­˜åˆ°: {json_file}")
            
            browser.quit()
            
            # éªŒè¯æ˜¯å¦ä¸ºæ—¥è¯­ç‰ˆæœ¬
            if language == self.language or language == 'æœªçŸ¥':  # å…è®¸æœªçŸ¥è¯­è¨€
                logger.info(f"  âœ… æµ‹è¯•å®Œæˆï¼ŒæˆåŠŸè§£æç”µå½±ä¿¡æ¯")
                return True
            else:
                logger.warning(f"  âš ï¸  è¯­è¨€ä¸åŒ¹é…ï¼ŒæœŸæœ›: {self.language}, å®é™…: {language}")
                return True  # ä»ç„¶è®¤ä¸ºæµ‹è¯•æˆåŠŸï¼Œå› ä¸ºè§£æåˆ°äº†æ•°æ®
                
        except Exception as e:
            logger.error(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
            import traceback
            logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
            return False
    
    async def test_html_content_extraction(self):
        """æµ‹è¯•HTMLå†…å®¹æå–åŠŸèƒ½"""
        logger.info(f"=== æµ‹è¯•HTMLå†…å®¹æå–: {self.movie_code} ===")
        
        service = await self.setup_service()
        if not service:
            logger.error("æ— æ³•åˆ›å»ºæœåŠ¡å®ä¾‹ï¼Œè·³è¿‡æµ‹è¯•")
            return False
        
        try:
            # åˆ›å»ºæµè§ˆå™¨å®ä¾‹ï¼ˆæ— å¤´æ¨¡å¼ï¼‰
            from app.utils.drission_utils import CloudflareBypassBrowser
            
            browser = CloudflareBypassBrowser(headless=True)
            
            # æ„å»ºç”µå½±é¡µé¢URL
            movie_url = f"https://missav.ai/{self.language}/{self.movie_code}"
            logger.info(f"è®¿é—®URL: {movie_url}")
            
            # ç›´æ¥è®¿é—®ç”µå½±é¡µé¢
            success = browser.get(movie_url)
            if not success:
                logger.error("âŒ æ— æ³•è®¿é—®ç”µå½±é¡µé¢")
                browser.quit()
                return False
            
            # è·å–é¡µé¢HTMLå†…å®¹
            html_content = browser.get_html()
            if html_content:
                logger.info(f"âœ… æˆåŠŸè·å–HTMLå†…å®¹ï¼Œé•¿åº¦: {len(html_content)} å­—ç¬¦")
                
                # æ£€æŸ¥å…³é”®å†…å®¹
                if self.movie_code in html_content:
                    logger.info(f"  âœ… HTMLä¸­åŒ…å«ç”µå½±ä»£ç : {self.movie_code}")
                else:
                    logger.warning(f"  âš ï¸  HTMLä¸­æœªæ‰¾åˆ°ç”µå½±ä»£ç : {self.movie_code}")
                
                # æ£€æŸ¥æ˜¯å¦åŒ…å«è§†é¢‘ç›¸å…³å†…å®¹
                video_keywords = ['video', 'm3u8', 'stream', 'player']
                found_keywords = [kw for kw in video_keywords if kw.lower() in html_content.lower()]
                if found_keywords:
                    logger.info(f"  âœ… æ‰¾åˆ°è§†é¢‘ç›¸å…³å…³é”®è¯: {', '.join(found_keywords)}")
                else:
                    logger.warning("  âš ï¸  æœªæ‰¾åˆ°è§†é¢‘ç›¸å…³å…³é”®è¯")
                
                # ä¿å­˜HTMLå†…å®¹ç”¨äºè°ƒè¯•
                html_file = f"test_536VOLA_data/{self.movie_code}_{self.language}.html"
                os.makedirs("test_536VOLA_data", exist_ok=True)
                with open(html_file, 'w', encoding='utf-8') as f:
                    f.write(html_content)
                logger.info(f"  ğŸ’¾ HTMLå†…å®¹å·²ä¿å­˜åˆ°: {html_file}")
                
                browser.quit()
                return True
            else:
                logger.error("âŒ æ— æ³•è·å–HTMLå†…å®¹")
                browser.quit()
                return False
                
        except Exception as e:
            logger.error(f"âŒ HTMLå†…å®¹æå–æµ‹è¯•å‡ºé”™: {str(e)}")
            import traceback
            logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
            return False
    
    async def run_all_tests(self):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        logger.info("\n" + "="*60)
        logger.info(f"å¼€å§‹æµ‹è¯• {self.movie_code} æ—¥è¯­ç‰ˆæœ¬çˆ¬å–åŠŸèƒ½")
        logger.info("="*60)
        
        tests = [
            ("HTMLå†…å®¹æå–æµ‹è¯•", self.test_html_content_extraction),
            ("ç›´æ¥ç”µå½±é¡µé¢çˆ¬å–æµ‹è¯•", self.test_direct_movie_page_crawl),
        ]
        
        passed = 0
        total = len(tests)
        
        for test_name, test_func in tests:
            logger.info(f"\n--- {test_name} ---")
            try:
                result = await test_func()
                if result:
                    logger.info(f"âœ… {test_name} é€šè¿‡")
                    passed += 1
                else:
                    logger.error(f"âŒ {test_name} å¤±è´¥")
            except Exception as e:
                logger.error(f"âŒ {test_name} å¼‚å¸¸: {str(e)}")
        
        logger.info("\n" + "="*60)
        logger.info(f"æµ‹è¯•å®Œæˆ: {passed}/{total} é€šè¿‡")
        logger.info("="*60)
        
        return passed, total

async def main():
    """ä¸»å‡½æ•°"""
    tester = TestJAOnly536VOLA001()
    
    try:
        passed, total = await tester.run_all_tests()
        
        if passed == total:
            logger.info("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
            return 0
        else:
            logger.error(f"ğŸ’¥ {total - passed} ä¸ªæµ‹è¯•å¤±è´¥")
            return 1
            
    except KeyboardInterrupt:
        logger.info("\nâ¹ï¸  æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
        return 130
    except Exception as e:
        logger.error(f"ğŸ’¥ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿæœªé¢„æœŸçš„é”™è¯¯: {str(e)}")
        return 1

def batch_crawl_example():
    """æ‰¹é‡çˆ¬å–ç¤ºä¾‹"""
    # åˆ›å»ºæ‰¹é‡çˆ¬è™«å®ä¾‹
    crawler = BatchMovieCrawler(language="ja")
    
    # ç¤ºä¾‹ç”µå½±ä»£ç åˆ—è¡¨
    movie_codes = [
        "VOLA-001",
        # "HZHB-004",  # å¯ä»¥æ·»åŠ æ›´å¤šç”µå½±ä»£ç 
        # "ABCD-123",
    ]
    
    # æ‰§è¡Œæ‰¹é‡çˆ¬å–
    results = crawler.crawl_movies(movie_codes)
    
    return results


def test_specific_movies():
    """æµ‹è¯•æŒ‡å®šçš„ç”µå½±ä»£ç ï¼ˆé¡ºåºçˆ¬å–ï¼‰"""
    logger.info("å¼€å§‹æµ‹è¯•æŒ‡å®šç”µå½±çš„æ‰¹é‡çˆ¬å–...")
    
    # åˆ›å»ºæ‰¹é‡çˆ¬è™«å®ä¾‹
    crawler = BatchMovieCrawler(language="ja")
    
    # ç”¨æˆ·æŒ‡å®šçš„ç”µå½±ä»£ç åˆ—è¡¨
    movie_codes = [
        "HZHB-004",
        "VERO-085", 
        "TW-02677",
        "PPT-028"
    ]
    
    # ä½¿ç”¨å•ä¸ªæµè§ˆå™¨å®ä¾‹æ‰§è¡Œæ‰¹é‡çˆ¬å–
    results = crawler.crawl_movies_single_browser(movie_codes, "test_movies_batch.jsonl")
    
    logger.info(f"\næµ‹è¯•å®Œæˆï¼è¯¦ç»†ç»“æœè¯·æŸ¥çœ‹: {crawler.test_data_dir / 'test_movies_batch.jsonl'}")
    return results


def test_concurrent_movies():
    """æµ‹è¯•æŒ‡å®šçš„ç”µå½±ä»£ç ï¼ˆå¹¶å‘çˆ¬å–ï¼‰"""
    logger.info("å¼€å§‹æµ‹è¯•æŒ‡å®šç”µå½±çš„å¹¶å‘æ‰¹é‡çˆ¬å–...")
    
    # åˆ›å»ºæ‰¹é‡çˆ¬è™«å®ä¾‹
    crawler = BatchMovieCrawler(language="ja")
    
    # ç”¨æˆ·æŒ‡å®šçš„ç”µå½±ä»£ç åˆ—è¡¨
    movie_codes = [
        "HZHB-004",
        "VERO-085", 
        "TW-02677",
        "PPT-028"
    ]
    
    # æ‰§è¡Œå¹¶å‘æ‰¹é‡çˆ¬å–ï¼ˆä½¿ç”¨å¤šä¸ªæ ‡ç­¾é¡µï¼‰
    results = crawler.crawl_movies_concurrent_tabs(
        movie_codes=movie_codes,
        output_file="test_movies_concurrent.jsonl",
        max_tabs=3  # æœ€å¤š3ä¸ªå¹¶å‘æ ‡ç­¾é¡µ
    )
    
    logger.info(f"\nå¹¶å‘æµ‹è¯•å®Œæˆï¼è¯¦ç»†ç»“æœè¯·æŸ¥çœ‹: {crawler.test_data_dir / 'test_movies_concurrent.jsonl'}")
    return results


def read_jsonl_example():
    """æ¼”ç¤ºå¦‚ä½•æµå¼è¯»å–JSONLæ–‡ä»¶"""
    logger.info("=== JSONLæ–‡ä»¶æµå¼è¯»å–ç¤ºä¾‹ ===")
    
    jsonl_file = Path("test_536VOLA_data") / "test_movies_batch.jsonl"
    
    if not jsonl_file.exists():
        logger.error(f"JSONLæ–‡ä»¶ä¸å­˜åœ¨: {jsonl_file}")
        return
    
    logger.info(f"æ­£åœ¨æµå¼è¯»å–æ–‡ä»¶: {jsonl_file}")
    
    # æµå¼è¯»å–JSONLæ–‡ä»¶ - æ¯æ¬¡åªåŠ è½½ä¸€è¡Œåˆ°å†…å­˜
    movie_count = 0
    with open(jsonl_file, 'r', encoding='utf-8') as f:
        for line_num, line in enumerate(f, 1):
            try:
                # è§£ææ¯ä¸€è¡Œçš„JSONå¯¹è±¡
                movie_data = json.loads(line.strip())
                movie_count += 1
                
                # æå–å…³é”®ä¿¡æ¯
                movie_id = movie_data.get('id', 'Unknown')
                title = movie_data.get('title', 'No Title')
                duration = movie_data.get('duration_seconds', 0)
                actresses = movie_data.get('actresses', [])
                
                logger.info(f"ç¬¬{line_num}è¡Œ - ID: {movie_id}")
                logger.info(f"  æ ‡é¢˜: {title[:50]}{'...' if len(title) > 50 else ''}")
                logger.info(f"  æ—¶é•¿: {duration}ç§’ ({duration//60}åˆ†{duration%60}ç§’)")
                logger.info(f"  å¥³ä¼˜: {', '.join(actresses[:3])}{'...' if len(actresses) > 3 else ''}")
                logger.info("  " + "-" * 50)
                
            except json.JSONDecodeError as e:
                logger.error(f"ç¬¬{line_num}è¡ŒJSONè§£æé”™è¯¯: {e}")
            except Exception as e:
                logger.error(f"ç¬¬{line_num}è¡Œå¤„ç†é”™è¯¯: {e}")
    
    logger.info(f"\n=== æµå¼è¯»å–å®Œæˆ ===")
    logger.info(f"æ€»å…±å¤„ç†äº† {movie_count} ä¸ªç”µå½±å¯¹è±¡")
    logger.info(f"JSONLä¼˜åŠ¿: å³ä½¿æ–‡ä»¶æœ‰20ä¸‡è¡Œï¼Œå†…å­˜å ç”¨ä¹Ÿå¾ˆå°‘ï¼Œå› ä¸ºæ¯æ¬¡åªåŠ è½½ä¸€è¡Œ")


def interactive_batch_crawl():
    """äº¤äº’å¼æ‰¹é‡çˆ¬å–"""
    print("=== MissAV æ‰¹é‡ç”µå½±çˆ¬è™« ===")
    print("è¯·è¾“å…¥è¦çˆ¬å–çš„ç”µå½±ä»£ç ï¼Œæ¯è¡Œä¸€ä¸ªï¼Œè¾“å…¥ç©ºè¡Œç»“æŸï¼š")
    
    movie_codes = []
    while True:
        code = input("ç”µå½±ä»£ç : ").strip()
        if not code:
            break
        movie_codes.append(code)
    
    if not movie_codes:
        print("æœªè¾“å…¥ä»»ä½•ç”µå½±ä»£ç ")
        return
    
    print(f"\nå°†è¦çˆ¬å– {len(movie_codes)} ä¸ªç”µå½±: {', '.join(movie_codes)}")
    confirm = input("ç¡®è®¤å¼€å§‹çˆ¬å–ï¼Ÿ(y/N): ").strip().lower()
    
    if confirm == 'y':
        crawler = BatchMovieCrawler(language="ja")
        results = crawler.crawl_movies(movie_codes)
        
        print("\n=== çˆ¬å–å®Œæˆ ===")
        print(f"æˆåŠŸ: {len(results['success'])} ä¸ª")
        print(f"å¤±è´¥: {len(results['failed'])} ä¸ª")
        
        return results
    else:
        print("å·²å–æ¶ˆ")
        return None


if __name__ == "__main__":
    import sys

    if len(sys.argv) > 1 and sys.argv[1] == "batch":
        # äº¤äº’å¼æ‰¹é‡çˆ¬å–
        interactive_batch_crawl()
    elif len(sys.argv) > 1 and sys.argv[1] == "example":
        # æ‰¹é‡çˆ¬å–ç¤ºä¾‹
        batch_crawl_example()
    elif len(sys.argv) > 1 and sys.argv[1] == "test":
        # æµ‹è¯•æŒ‡å®šç”µå½±ï¼ˆé¡ºåºçˆ¬å–ï¼‰
        test_specific_movies()
    elif len(sys.argv) > 1 and sys.argv[1] == "concurrent":
        # æµ‹è¯•æŒ‡å®šç”µå½±ï¼ˆå¹¶å‘çˆ¬å–ï¼‰
        test_concurrent_movies()
    elif len(sys.argv) > 1 and sys.argv[1] == "read":
        # æ¼”ç¤ºJSONLæ–‡ä»¶è¯»å–
        read_jsonl_example()
    else:
        # è¿è¡ŒåŸæœ‰æµ‹è¯•
        exit_code = asyncio.run(main())
        sys.exit(exit_code)
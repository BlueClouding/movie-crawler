#!/usr/bin/env python3
"""
æµ‹è¯•uncensored-leakç”µå½±çš„æå–é—®é¢˜
ä¸“é—¨æ£€æŸ¥ä¸ºä»€ä¹ˆè¿™ç±»ç”µå½±æå–å¤±è´¥
"""

import json
import time
import sys
from pathlib import Path
from loguru import logger
from DrissionPage import ChromiumPage, ChromiumOptions

# å¯¼å…¥çˆ¬è™«
sys.path.append('.')
from simple_database_crawler import SimpleDatabaseCrawler

def test_uncensored_leak_movies():
    """æµ‹è¯•uncensored-leakç”µå½±æå–"""
    
    # æµ‹è¯•æ•°æ® - ä½ æåˆ°çš„æœ‰é—®é¢˜çš„ç”µå½±
    test_movies = [
        "gtj-061-uncensored-leak",
        "rbk-016-uncensored-leak",
        "gvg-340-uncensored-leak",  # ä¹‹å‰å¤±è´¥çš„
        "hmn-021-uncensored-leak",  # ä¹‹å‰æˆåŠŸçš„ï¼Œä½œä¸ºå¯¹æ¯”
    ]
    
    logger.info(f"ğŸ§ª æµ‹è¯• {len(test_movies)} éƒ¨uncensored-leakç”µå½±")
    
    # åˆ›å»ºçˆ¬è™«å®ä¾‹
    crawler = SimpleDatabaseCrawler()
    
    # åˆ›å»ºæµè§ˆå™¨
    options = ChromiumOptions()
    options.headless(False)
    options.set_argument('--window-size=1920,1080')
    
    browser = ChromiumPage(addr_or_opts=options)
    
    # å»ºç«‹ä¼šè¯
    browser.get("https://missav.ai/")
    time.sleep(2)
    
    results = []
    
    try:
        for i, movie_code in enumerate(test_movies, 1):
            logger.info(f"\nğŸ¬ æµ‹è¯• {i}/{len(test_movies)}: {movie_code}")
            
            url = f"https://missav.ai/ja/{movie_code}"
            logger.info(f"ğŸ“ URL: {url}")
            
            # è®¿é—®é¡µé¢
            browser.get(url)
            
            # ç­‰å¾…åŠ è½½
            for check in range(5):
                time.sleep(1)
                html = browser.html
                current_url = browser.url
                
                logger.info(f"â³ æ£€æŸ¥ {check+1}/5: HTMLé•¿åº¦={len(html) if html else 0}, URL={current_url}")
                
                if html and len(html) > 50000:
                    logger.info(f"âœ… é¡µé¢å·²å……åˆ†åŠ è½½")
                    break
                elif check == 4:
                    logger.warning(f"âš ï¸ é¡µé¢åŠ è½½å¯èƒ½ä¸å®Œæ•´")
            
            # è·å–æœ€ç»ˆçŠ¶æ€
            html = browser.html
            current_url = browser.url
            
            if html:
                # æ£€æŸ¥é‡å®šå‘
                final_movie_code = movie_code
                if current_url != url:
                    try:
                        final_movie_code = current_url.split('/')[-1]
                        logger.info(f"ğŸ”„ é‡å®šå‘: {movie_code} â†’ {final_movie_code}")
                    except:
                        logger.warning(f"âš ï¸ æ— æ³•ä»é‡å®šå‘URLæå–ä»£ç ")
                
                # æ£€æŸ¥404
                is_404 = crawler.check_404_or_not_found(html, current_url, url, final_movie_code)
                logger.info(f"ğŸ” 404æ£€æŸ¥ç»“æœ: {is_404}")
                
                if not is_404:
                    # å°è¯•æå–ä¿¡æ¯
                    logger.info(f"ğŸ¯ å¼€å§‹æå–ä¿¡æ¯ï¼Œä½¿ç”¨ä»£ç : {final_movie_code}")
                    
                    movie_info = crawler.extract_with_parse_movie_page(
                        html, 
                        999990 + i, 
                        final_movie_code,
                        current_url
                    )
                    
                    if movie_info:
                        # åˆ†ææå–ç»“æœ
                        m3u8_links = movie_info.get('m3u8_links', [])
                        m3u8_urls = movie_info.get('m3u8_urls', [])
                        magnet_links = movie_info.get('magnet_links', [])
                        title = movie_info.get('title', 'æœªçŸ¥')
                        extraction_status = movie_info.get('extraction_status', 'æœªçŸ¥')
                        
                        logger.info(f"ğŸ“Š æå–ç»“æœåˆ†æ:")
                        logger.info(f"  æ ‡é¢˜: {title[:50]}...")
                        logger.info(f"  M3U8 links: {len(m3u8_links)}")
                        logger.info(f"  M3U8 urls: {len(m3u8_urls)}")
                        logger.info(f"  ç£åŠ›é“¾æ¥: {len(magnet_links)}")
                        logger.info(f"  æå–çŠ¶æ€: {extraction_status}")
                        
                        # æ£€æŸ¥æ˜¯å¦æœ‰ä»»ä½•M3U8
                        total_m3u8 = len(m3u8_links) + len(m3u8_urls)
                        
                        if total_m3u8 > 0:
                            logger.info(f"âœ… {movie_code}: æˆåŠŸæå–M3U8 ({total_m3u8}ä¸ª)")
                            status = "success"
                        elif title and title != "æœªçŸ¥" and title != "uncensored-leak":
                            logger.info(f"âš ï¸ {movie_code}: æœ‰æ ‡é¢˜ä½†æ— M3U8")
                            status = "partial_success"
                        else:
                            logger.warning(f"ğŸš« {movie_code}: æå–å¤±è´¥")
                            status = "extraction_failed"
                        
                        results.append({
                            'movie_code': movie_code,
                            'final_code': final_movie_code,
                            'url': url,
                            'final_url': current_url,
                            'title': title,
                            'm3u8_count': total_m3u8,
                            'magnet_count': len(magnet_links),
                            'extraction_status': extraction_status,
                            'status': status,
                            'html_length': len(html)
                        })
                        
                        # å¦‚æœæå–å¤±è´¥ï¼Œè¿›è¡Œè¯¦ç»†åˆ†æ
                        if status == "extraction_failed":
                            logger.info(f"ğŸ” è¯¦ç»†åˆ†æ {movie_code}:")
                            
                            # æ£€æŸ¥HTMLä¸­æ˜¯å¦åŒ…å«M3U8
                            import re
                            m3u8_in_html = re.findall(r'https?://[^"\'>\s]+\.m3u8[^"\'>\s]*', html)
                            logger.info(f"  HTMLä¸­çš„M3U8: {len(m3u8_in_html)}")
                            
                            # æ£€æŸ¥æ˜¯å¦åŒ…å«magnet
                            magnet_in_html = re.findall(r'magnet:\?[^"\'>\s]+', html)
                            logger.info(f"  HTMLä¸­çš„ç£åŠ›: {len(magnet_in_html)}")
                            
                            # æ£€æŸ¥æ˜¯å¦åŒ…å«ç”µå½±ä»£ç 
                            code_in_html = movie_code.lower() in html.lower()
                            logger.info(f"  åŒ…å«ç”µå½±ä»£ç : {code_in_html}")
                            
                            # æ£€æŸ¥é¡µé¢ç±»å‹
                            if "é¦–é¡µ" in html or "homepage" in html.lower():
                                logger.info(f"  é¡µé¢ç±»å‹: å¯èƒ½æ˜¯é¦–é¡µ")
                            elif "404" in html.lower():
                                logger.info(f"  é¡µé¢ç±»å‹: å¯èƒ½æ˜¯404é¡µé¢")
                            else:
                                logger.info(f"  é¡µé¢ç±»å‹: æ­£å¸¸ç”µå½±é¡µé¢")
                    else:
                        logger.error(f"âŒ {movie_code}: æå–æ–¹æ³•è¿”å›None")
                        results.append({
                            'movie_code': movie_code,
                            'final_code': final_movie_code,
                            'url': url,
                            'final_url': current_url,
                            'status': 'extraction_method_failed',
                            'html_length': len(html)
                        })
                else:
                    logger.error(f"ğŸš« {movie_code}: æ£€æµ‹ä¸º404é¡µé¢")
                    results.append({
                        'movie_code': movie_code,
                        'url': url,
                        'final_url': current_url,
                        'status': '404_detected',
                        'html_length': len(html)
                    })
            else:
                logger.error(f"âŒ {movie_code}: æ— æ³•è·å–é¡µé¢å†…å®¹")
                results.append({
                    'movie_code': movie_code,
                    'url': url,
                    'status': 'no_html_content'
                })
            
            # é—´éš”
            if i < len(test_movies):
                time.sleep(3)
    
    finally:
        browser.quit()
        logger.info("ğŸ”’ æµè§ˆå™¨å·²å…³é—­")
    
    # ä¿å­˜è¯¦ç»†ç»“æœ
    output_file = Path("uncensored_leak_test_results.json")
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    logger.info(f"ğŸ’¾ è¯¦ç»†åˆ†æç»“æœå·²ä¿å­˜åˆ°: {output_file}")
    
    # ç»Ÿè®¡ç»“æœ
    success_count = len([r for r in results if r.get('status') == 'success'])
    partial_count = len([r for r in results if r.get('status') == 'partial_success'])
    failed_count = len([r for r in results if r.get('status') in ['extraction_failed', 'extraction_method_failed']])
    not_found_count = len([r for r in results if r.get('status') == '404_detected'])
    
    logger.info(f"\n{'='*50}")
    logger.info("ğŸ“Š uncensored-leakç”µå½±æµ‹è¯•ç»“æœ")
    logger.info(f"æ€»æ•°: {len(test_movies)}")
    logger.info(f"âœ… å®Œå…¨æˆåŠŸ: {success_count}")
    logger.info(f"âš ï¸ éƒ¨åˆ†æˆåŠŸ: {partial_count}")
    logger.info(f"ğŸ’€ æå–å¤±è´¥: {failed_count}")
    logger.info(f"ğŸš« 404ä¸å­˜åœ¨: {not_found_count}")
    
    # è¯¦ç»†ç»“æœ
    for result in results:
        status_emoji = {
            'success': 'âœ…',
            'partial_success': 'âš ï¸',
            'extraction_failed': 'ğŸ’€',
            'extraction_method_failed': 'âŒ',
            '404_detected': 'ğŸš«',
            'no_html_content': 'ğŸ’¥'
        }.get(result.get('status'), 'â“')
        
        m3u8_info = f" (M3U8: {result.get('m3u8_count', 0)})" if result.get('m3u8_count') is not None else ""
        logger.info(f"{status_emoji} {result['movie_code']}: {result.get('status', 'unknown')}{m3u8_info}")
    
    return results

if __name__ == "__main__":
    logger.info("ğŸ§ª å¼€å§‹æµ‹è¯•uncensored-leakç”µå½±æå–é—®é¢˜")
    logger.info("ğŸ¯ æ£€æŸ¥ä¸ºä»€ä¹ˆè¿™ç±»ç”µå½±åœ¨æµè§ˆå™¨æœ‰æ•°æ®ä½†æå–å¤±è´¥")
    
    results = test_uncensored_leak_movies()
    
    logger.info("\nğŸ‰ æµ‹è¯•å®Œæˆï¼")
    logger.info("ğŸ’¡ æ ¹æ®ç»“æœå¯ä»¥åˆ†æuncensored-leakç”µå½±çš„æå–é—®é¢˜")

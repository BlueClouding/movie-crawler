#!/usr/bin/env python3
"""
æµ‹è¯•URLä¿®æ­£åŠŸèƒ½
ä¸“é—¨æµ‹è¯•uncensored-leaked -> uncensored-leakçš„ä¿®æ­£
"""

import json
import time
import random
import sys
from pathlib import Path
from loguru import logger
from DrissionPage import ChromiumPage, ChromiumOptions
from sqlalchemy import create_engine, text
from sqlalchemy.orm import sessionmaker

# å¯¼å…¥MovieDetailCrawler
sys.path.append(str(Path(__file__).parent / "src"))
try:
    from test.test_drission_movie import MovieDetailCrawler
    HAS_MOVIE_CRAWLER = True
    logger.info("âœ… æˆåŠŸå¯¼å…¥MovieDetailCrawler")
except ImportError as e:
    HAS_MOVIE_CRAWLER = False
    logger.warning(f"âŒ æ— æ³•å¯¼å…¥MovieDetailCrawler: {e}")

def test_url_correction():
    """æµ‹è¯•URLä¿®æ­£åŠŸèƒ½"""
    
    # æ•°æ®åº“è¿æ¥
    db_url = "postgresql://postgres:123456@localhost:5432/movie_crawler"
    engine = create_engine(db_url)
    Session = sessionmaker(bind=engine)
    
    # è·å–uncensored-leakedç”µå½±
    session = Session()
    try:
        result = session.execute(text("""
            SELECT id, link 
            FROM movies 
            WHERE link LIKE '%uncensored-leaked%' 
            LIMIT 3
        """))
        raw_movies = [(row.id, row.link) for row in result]
    finally:
        session.close()
    
    logger.info(f"ğŸ“Š æ‰¾åˆ° {len(raw_movies)} éƒ¨uncensored-leakedç”µå½±")
    
    # æµ‹è¯•URLä¿®æ­£é€»è¾‘
    corrected_movies = []
    for movie_id, link in raw_movies:
        if link.startswith('dm3/v/') or link.startswith('dm4/v/'):
            movie_code = link.split('/')[-1]
            # ä¿®æ­£uncensored-leakedä¸ºuncensored-leak
            if movie_code.endswith('-uncensored-leaked'):
                original_code = movie_code
                movie_code = movie_code.replace('-uncensored-leaked', '-uncensored-leak')
                logger.info(f"ğŸ”§ ä¿®æ­£URL: ID={movie_id}, {original_code} â†’ {movie_code}")
            full_url = f"https://missav.ai/ja/{movie_code}"
            corrected_movies.append((movie_id, full_url, movie_code))
    
    # åˆ›å»ºæµè§ˆå™¨æµ‹è¯•
    logger.info("ğŸš€ åˆ›å»ºæµè§ˆå™¨æµ‹è¯•ä¿®æ­£åçš„URL")
    
    options = ChromiumOptions()
    options.headless(False)
    options.set_argument('--window-size=1920,1080')
    
    browser = ChromiumPage(addr_or_opts=options)
    
    # å»ºç«‹ä¼šè¯
    browser.get("https://missav.ai/")
    time.sleep(2)
    
    results = []
    
    try:
        for i, (movie_id, movie_url, movie_code) in enumerate(corrected_movies, 1):
            logger.info(f"\nğŸ¬ æµ‹è¯• {i}/{len(corrected_movies)}: ID={movie_id}, {movie_code}")
            logger.info(f"ğŸ“ URL: {movie_url}")
            
            # è®¿é—®é¡µé¢
            browser.get(movie_url)
            
            # ç­‰å¾…åŠ è½½
            for check in range(3):
                time.sleep(1)
                html = browser.html
                current_url = browser.url
                
                if html and len(html) > 50000:
                    logger.info(f"âœ… é¡µé¢å·²åŠ è½½ ({len(html)} å­—ç¬¦)")
                    if current_url != movie_url:
                        logger.info(f"ğŸ”„ æœ€ç»ˆURL: {current_url}")
                    break
            
            # æ£€æŸ¥é¡µé¢å†…å®¹
            html = browser.html
            if html and len(html) > 10000:
                # ç®€å•æ£€æŸ¥æ˜¯å¦åŒ…å«ç”µå½±ç›¸å…³å†…å®¹
                html_lower = html.lower()
                if any(keyword in html_lower for keyword in ['video', 'movie', 'player', 'download', 'm3u8']):
                    logger.info(f"âœ… {movie_code}: URLä¿®æ­£æˆåŠŸï¼Œé¡µé¢åŒ…å«ç”µå½±å†…å®¹")
                    
                    # å°è¯•æå–ä¿¡æ¯
                    if HAS_MOVIE_CRAWLER:
                        try:
                            crawler = MovieDetailCrawler(movie_code)
                            result = crawler.parse_movie_page(html)
                            if result and result.get('title'):
                                logger.info(f"ğŸ¬ æˆåŠŸæå–æ ‡é¢˜: {result['title'][:50]}...")
                                results.append({
                                    'id': movie_id,
                                    'code': movie_code,
                                    'url': movie_url,
                                    'final_url': current_url,
                                    'title': result['title'],
                                    'status': 'success'
                                })
                            else:
                                logger.warning(f"âš ï¸ {movie_code}: é¡µé¢åŠ è½½æˆåŠŸä½†ä¿¡æ¯æå–å¤±è´¥")
                                results.append({
                                    'id': movie_id,
                                    'code': movie_code,
                                    'url': movie_url,
                                    'final_url': current_url,
                                    'status': 'extraction_failed'
                                })
                        except Exception as e:
                            logger.error(f"âŒ {movie_code}: æå–è¿‡ç¨‹å‡ºé”™: {e}")
                            results.append({
                                'id': movie_id,
                                'code': movie_code,
                                'url': movie_url,
                                'final_url': current_url,
                                'status': 'error',
                                'error': str(e)
                            })
                    else:
                        logger.info(f"âœ… {movie_code}: URLä¿®æ­£æˆåŠŸï¼ˆæœªæµ‹è¯•ä¿¡æ¯æå–ï¼‰")
                        results.append({
                            'id': movie_id,
                            'code': movie_code,
                            'url': movie_url,
                            'final_url': current_url,
                            'status': 'page_loaded'
                        })
                else:
                    logger.warning(f"ğŸš« {movie_code}: é¡µé¢ä¸åŒ…å«ç”µå½±ç›¸å…³å†…å®¹ï¼Œå¯èƒ½æ˜¯404")
                    results.append({
                        'id': movie_id,
                        'code': movie_code,
                        'url': movie_url,
                        'final_url': current_url,
                        'status': '404'
                    })
            else:
                logger.error(f"âŒ {movie_code}: é¡µé¢å†…å®¹ä¸è¶³")
                results.append({
                    'id': movie_id,
                    'code': movie_code,
                    'url': movie_url,
                    'status': 'page_load_failed'
                })
            
            # é—´éš”
            if i < len(corrected_movies):
                time.sleep(random.uniform(3, 6))
    
    finally:
        browser.quit()
        logger.info("ğŸ”’ æµè§ˆå™¨å·²å…³é—­")
    
    # è¾“å‡ºç»“æœ
    logger.info(f"\n{'='*50}")
    logger.info("ğŸ“Š URLä¿®æ­£æµ‹è¯•ç»“æœ")
    logger.info(f"æ€»æ•°: {len(corrected_movies)}")
    logger.info(f"æˆåŠŸ: {len([r for r in results if r['status'] == 'success'])}")
    logger.info(f"é¡µé¢åŠ è½½æˆåŠŸ: {len([r for r in results if r['status'] in ['success', 'page_loaded']])}")
    logger.info(f"404: {len([r for r in results if r['status'] == '404'])}")
    
    # ä¿å­˜ç»“æœ
    output_file = Path("url_correction_test_results.json")
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    logger.info(f"ğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
    
    return results

if __name__ == "__main__":
    logger.info("ğŸ§ª å¼€å§‹æµ‹è¯•URLä¿®æ­£åŠŸèƒ½")
    logger.info("ğŸ¯ æµ‹è¯•uncensored-leaked â†’ uncensored-leakä¿®æ­£")
    
    results = test_url_correction()
    
    logger.info("\nğŸ‰ æµ‹è¯•å®Œæˆï¼")
    for result in results:
        status_emoji = {
            'success': 'âœ…',
            'page_loaded': 'ğŸ“„',
            '404': 'ğŸš«',
            'extraction_failed': 'âš ï¸',
            'error': 'âŒ',
            'page_load_failed': 'ğŸ’€'
        }.get(result['status'], 'â“')
        
        logger.info(f"{status_emoji} {result['code']}: {result['status']}")

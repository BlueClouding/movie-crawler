#!/usr/bin/env python3
"""
å¿«é€Ÿæ‰¹é‡çˆ¬è™«
åŸºäºæˆåŠŸçš„å¿«é€Ÿæ–¹æ³•ï¼Œå¤„ç†å¤§é‡ç”µå½±
"""

import time
import random
import json
from pathlib import Path
from loguru import logger
from DrissionPage import ChromiumPage, ChromiumOptions

class FastBatchCrawler:
    """å¿«é€Ÿæ‰¹é‡çˆ¬è™«"""
    
    def __init__(self):
        self.results = []
        self.failed_movies = []
        self.browser = None
        
    def create_fast_browser(self):
        """åˆ›å»ºå¿«é€Ÿæµè§ˆå™¨"""
        options = ChromiumOptions()
        options.headless(False)  # å¯ä»¥æ”¹ä¸ºTrueæ¥éšè—æµè§ˆå™¨
        options.set_argument('--window-size=1920,1080')
        options.set_argument('--disable-blink-features=AutomationControlled')
        
        self.browser = ChromiumPage(addr_or_opts=options)
        logger.info("ğŸš€ å¿«é€Ÿæµè§ˆå™¨åˆ›å»ºæˆåŠŸ")
        
        # å¿«é€Ÿå»ºç«‹ä¼šè¯
        logger.info("ğŸ“± å»ºç«‹ä¼šè¯...")
        self.browser.get("https://missav.ai/")
        time.sleep(2)
        
        try:
            self.browser.scroll(300)
            time.sleep(0.5)
            self.browser.scroll(0)
        except:
            pass
        
        logger.info("âœ… ä¼šè¯å»ºç«‹å®Œæˆ")
    
    def fast_extract_info(self, movie_code):
        """å¿«é€Ÿæå–ç”µå½±ä¿¡æ¯"""
        try:
            html = self.browser.html
            if not html or len(html) < 1000:
                return None
            
            html_lower = html.lower()
            
            # å¿«é€Ÿå†…å®¹æ£€æŸ¥
            movie_indicators = 0
            if 'missav' in html_lower:
                movie_indicators += 1
            if movie_code.lower() in html_lower:
                movie_indicators += 1
            if any(word in html_lower for word in ['video', 'movie', 'player']):
                movie_indicators += 1
            
            if movie_indicators < 2:
                return None
            
            # å¿«é€Ÿæå–åŸºæœ¬ä¿¡æ¯
            info = {
                'code': movie_code,
                'url': self.browser.url,
                'timestamp': time.time(),
                'page_length': len(html)
            }
            
            # æå–æ ‡é¢˜
            try:
                title_element = self.browser.ele('tag:h1')
                if title_element:
                    info['title'] = title_element.text.strip()
                else:
                    info['title'] = "æœªçŸ¥æ ‡é¢˜"
            except:
                info['title'] = "æœªçŸ¥æ ‡é¢˜"
            
            # æ£€æŸ¥è§†é¢‘å†…å®¹
            info['has_video_content'] = 'm3u8' in html_lower or 'video' in html_lower
            info['magnet_count'] = html_lower.count('magnet:')
            
            return info
            
        except Exception as e:
            logger.error(f"æå–ä¿¡æ¯å‡ºé”™: {e}")
            return None
    
    def crawl_single_movie(self, movie_code):
        """çˆ¬å–å•ä¸ªç”µå½±ï¼ˆè¶…å¿«é€Ÿï¼‰"""
        url = f"https://missav.ai/ja/{movie_code}"
        logger.info(f"ğŸ“ è®¿é—®: {movie_code}")
        
        try:
            # è®¿é—®é¡µé¢
            self.browser.get(url)
            
            # å¿«é€Ÿæ£€æŸ¥åŠ è½½çŠ¶æ€ï¼ˆæœ€å¤š2ç§’ï¼‰
            for check in range(2):
                time.sleep(1)
                html_length = len(self.browser.html) if self.browser.html else 0
                
                if html_length > 50000:
                    logger.info(f"âœ… {movie_code} é¡µé¢å·²åŠ è½½ ({html_length} å­—ç¬¦)")
                    break
            
            # å¿«é€Ÿæ»šåŠ¨
            try:
                self.browser.scroll(500)
                time.sleep(0.3)
                self.browser.scroll(0)
            except:
                pass
            
            # æå–ä¿¡æ¯
            movie_info = self.fast_extract_info(movie_code)
            
            if movie_info:
                self.results.append(movie_info)
                logger.info(f"âœ… {movie_code}: {movie_info.get('title', 'æœªçŸ¥')[:30]}...")
                return True
            else:
                self.failed_movies.append(movie_code)
                logger.error(f"âŒ {movie_code}: ä¿¡æ¯æå–å¤±è´¥")
                return False
                
        except Exception as e:
            logger.error(f"âŒ {movie_code}: {e}")
            self.failed_movies.append(movie_code)
            return False
    
    def batch_crawl(self, movie_codes, save_interval=10):
        """æ‰¹é‡çˆ¬å–ç”µå½±"""
        logger.info(f"ğŸš€ å¼€å§‹å¿«é€Ÿæ‰¹é‡çˆ¬å– {len(movie_codes)} éƒ¨ç”µå½±")
        
        # åˆ›å»ºæµè§ˆå™¨
        self.create_fast_browser()
        
        start_time = time.time()
        
        try:
            for i, movie_code in enumerate(movie_codes, 1):
                logger.info(f"\nğŸ¬ [{i}/{len(movie_codes)}] {movie_code}")
                
                # çˆ¬å–ç”µå½±
                success = self.crawl_single_movie(movie_code)
                
                # å®šæœŸä¿å­˜ç»“æœ
                if i % save_interval == 0:
                    self.save_results()
                    elapsed = time.time() - start_time
                    avg_time = elapsed / i
                    remaining = (len(movie_codes) - i) * avg_time
                    logger.info(f"ğŸ“Š è¿›åº¦: {i}/{len(movie_codes)}, å¹³å‡ {avg_time:.1f}ç§’/éƒ¨, é¢„è®¡å‰©ä½™ {remaining/60:.1f}åˆ†é’Ÿ")
                
                # å¿«é€Ÿé—´éš”
                if i < len(movie_codes):
                    wait_time = random.uniform(2, 5)  # 2-5ç§’
                    time.sleep(wait_time)
        
        finally:
            # æœ€ç»ˆä¿å­˜
            self.save_results()
            
            # å…³é—­æµè§ˆå™¨
            if self.browser:
                try:
                    self.browser.quit()
                    logger.info("ğŸ”’ æµè§ˆå™¨å·²å…³é—­")
                except:
                    pass
        
        # è¾“å‡ºç»Ÿè®¡
        total_time = time.time() - start_time
        success_count = len(self.results)
        failed_count = len(self.failed_movies)
        
        logger.info(f"\n{'='*50}")
        logger.info(f"ğŸ“Š æ‰¹é‡çˆ¬å–å®Œæˆ")
        logger.info(f"æ€»æ•°: {len(movie_codes)}")
        logger.info(f"æˆåŠŸ: {success_count}")
        logger.info(f"å¤±è´¥: {failed_count}")
        logger.info(f"æˆåŠŸç‡: {success_count/len(movie_codes)*100:.1f}%")
        logger.info(f"æ€»æ—¶é—´: {total_time/60:.1f} åˆ†é’Ÿ")
        logger.info(f"å¹³å‡é€Ÿåº¦: {total_time/len(movie_codes):.1f} ç§’/éƒ¨")
        
        return self.results
    
    def save_results(self):
        """ä¿å­˜ç»“æœåˆ°æ–‡ä»¶"""
        if self.results:
            # ä¿å­˜æˆåŠŸç»“æœ
            success_file = Path("fast_crawl_results.json")
            with open(success_file, 'w', encoding='utf-8') as f:
                json.dump(self.results, f, ensure_ascii=False, indent=2)
            logger.info(f"ğŸ’¾ æˆåŠŸç»“æœå·²ä¿å­˜: {success_file} ({len(self.results)} éƒ¨)")
        
        if self.failed_movies:
            # ä¿å­˜å¤±è´¥åˆ—è¡¨
            failed_file = Path("failed_movies.json")
            with open(failed_file, 'w', encoding='utf-8') as f:
                json.dump(self.failed_movies, f, ensure_ascii=False, indent=2)
            logger.info(f"ğŸ“ å¤±è´¥åˆ—è¡¨å·²ä¿å­˜: {failed_file} ({len(self.failed_movies)} éƒ¨)")

def main():
    """ä¸»å‡½æ•°"""
    
    # æµ‹è¯•ç”µå½±åˆ—è¡¨ï¼ˆå¯ä»¥æ‰©å±•åˆ°æ›´å¤šï¼‰
    test_movies = [
        "ipzz-562", "sone-718", "ngod-266",
        "dass-659", "jur-320", "ure-122",
        "ipzz-563", "sone-719", "ngod-267",
        "dass-660", "jur-321", "ure-123"
    ]
    
    logger.info("ğŸš€ å¿«é€Ÿæ‰¹é‡çˆ¬è™«")
    logger.info(f"ğŸ“‹ å‡†å¤‡çˆ¬å– {len(test_movies)} éƒ¨ç”µå½±")
    logger.info("âš¡ é¢„è®¡é€Ÿåº¦: ~10ç§’/éƒ¨")
    logger.info(f"ğŸ• é¢„è®¡æ€»æ—¶é—´: ~{len(test_movies)*10/60:.1f} åˆ†é’Ÿ")
    
    # è¯¢é—®æ˜¯å¦å¼€å§‹
    start = input(f"\nğŸš€ å¼€å§‹çˆ¬å– {len(test_movies)} éƒ¨ç”µå½±? [y/n]: ").lower()
    if start != 'y':
        logger.info("ğŸ‘‹ ä¸‹æ¬¡è§ï¼")
        return
    
    # åˆ›å»ºçˆ¬è™«å¹¶å¼€å§‹
    crawler = FastBatchCrawler()
    results = crawler.batch_crawl(test_movies, save_interval=5)
    
    # æ˜¾ç¤ºéƒ¨åˆ†ç»“æœ
    if results:
        logger.info("\nğŸ¬ æˆåŠŸçˆ¬å–çš„ç”µå½±:")
        for result in results[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
            logger.info(f"  âœ… {result['code']}: {result.get('title', 'æœªçŸ¥')[:40]}...")
        
        if len(results) > 5:
            logger.info(f"  ... è¿˜æœ‰ {len(results)-5} éƒ¨ç”µå½±")

if __name__ == "__main__":
    main()
